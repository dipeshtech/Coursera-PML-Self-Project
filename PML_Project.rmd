---
title: Practical Machine Learning Project - Prediction Analysis on Weight Lifting Exercise Dataset
  Report
author: "by Dipesh Kumar Singh"
output:
  html_document:
    fig_height: 9
    fig_width: 9
---

## Introduction  

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit has made possible to collect large amount of data about personal activity without incurring much cost. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. The purpose of this exercise is how well an activity was an activity was performed by the individual. "how (well)" investigation has only received little attention so far, even though it potentially provides useful information for a large variety of applications,such as sports training.

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3dj0VFTzd

Class Specifications:
Class A : Dumbbell Biceps Curl in five different fashions
Class B : throwing the elbows to the front
Class C : lifting the dumbbell only halfway
Class D : lowering the dumbbell only halfway
Class E : throwing the hips to the front 


In this project, the dataset is collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise.  


## Data Preparation  
```{r, cache = T}
library(randomForest)
library(corrplot)
library(caret)
library(rpart)
library(rpart.plot)

```
### Download the Data
```{r, cache = T}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFilePath <- "./data/pml-training.csv"
testFilePath  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFilePath)) {
  download.file(trainUrl, destfile=trainFilePath, method="curl")
}
if (!file.exists(testFilePath)) {
  download.file(testUrl, destfile=testFilePath, method="curl")
}
```  

### Read the Data
After downloading the data from the source location, we can read the content of csv files into two data frames.  
```{r, cache = T}
trainRaw <- read.csv("./data/pml-training.csv")
testRaw <- read.csv("./data/pml-testing.csv")
dim(trainRaw)
dim(testRaw)
```

The training data set contains 19622 observations and 160 variables, while the testing data set contains 20 observations and 160 variables. The "classe" variable in the training set is the outcome to predict. 

The names of all the variables, "classe" being the 160th variable.
```{r, cache=TRUE}
names(trainRaw)

```


### Clean the data
We will keep relevant variables and get rid of the rest.

First, we remove columns that contain NA missing values.
```{r, cache = T}
trainRaw <- trainRaw[, colSums(is.na(trainRaw)) == 0] 
testRaw <- testRaw[, colSums(is.na(testRaw)) == 0] 
```  

Next, we get rid of attributes which do not contribute much to the accelerometer measurements. Like '^timestamp' etc which is to purpose warehousing needs and not relevant for this analysis.

```{r, cache = T}
final_class <- trainRaw$classe
trainFilter <- grepl("^X|timestamp|window|username", names(trainRaw))
train_OnlyImpFeatures <- trainRaw[, !trainFilter]
trainCleaned <- train_OnlyImpFeatures[, sapply(train_OnlyImpFeatures, is.numeric)]

trainCleaned$classe <- final_class

testFilter <- grepl("^X|timestamp|window|username", names(testRaw))
test_OnlyImpFeatures <- testRaw[, !testFilter]
testCleaned <- test_OnlyImpFeatures[, sapply(test_OnlyImpFeatures, is.numeric)]

names(trainCleaned)
```

The number of variables reduced from 160 to 53. Now, the cleaned training data set contains 19622 observations and 53 variables, while the testing data set contains 20 observations and 53 variables. The "classe" variable is still exist in the cleaned training set.

### Data Slicing
Then, we can split the cleaned training set into a pure training data set (70%) and a validation data set (30%). We will use the validation data set to conduct cross validation in future steps.


```{r, cache = T}
set.seed(12345) 
inTrain <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainData <- trainCleaned[inTrain, ]
testData <- trainCleaned[-inTrain, ]
```

## Fitting the model

We fit a predictive model for activity recognition using **Random Forest** algorithm because it automatically selects important variables and is robust to correlated covariates & outliers in general. We will set training control parameter to 5 for **5-fold cross validation** when applying the algorithm.  

```{r, cache = T}
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
modelRf
```

## Performance Evaluation

Next, we estimate the performance of the model on the validation data set.  

```{r, cache = T}
predictRf <- predict(modelRf, testData)
confusionMatrix(testData$classe, predictRf)

```


```{r, cache = T}
accuracy <- postResample(predictRf, testData$classe)
accuracy
ooserr <- 1 - as.numeric(confusionMatrix(testData$classe, predictRf)$overall[1])
ooserr
```

The accuracy is **0.9889550** and kappa is ***0.9860251**.


## Predicting on the test Data Set
We now apply the model to the original testing data set downloaded from the data source. 

```{r, cache = T}
result <- predict(modelRf, testCleaned[, -length(names(testCleaned))])
result
```  


## Appendix: Visulaization

1. Decision Tree Visualization

```{r, cache = T}
treeModel <- rpart(classe ~ ., data=trainData, method="class")
prp(treeModel) 
```


